{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, shear_range=0.25,\n",
    "                                    zoom_range=0.25, width_shift_range=0.2, height_shift_range=0.2)\n",
    "training_set = train_data_gen.flow_from_directory('Data/dataset/training_set', target_size=(64,64), class_mode ='binary', batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data_gen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "testing_set = test_data_gen.flow_from_directory('Data/dataset/test_set', target_size=(64,64), class_mode='binary', batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "cnn = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convolutional layer\n",
    "cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
    "cnn.add(MaxPooling2D(pool_size=2))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.2))\n",
    "\n",
    "cnn.add(Conv2D(64, activation='relu', kernel_size=3))\n",
    "cnn.add(MaxPooling2D(pool_size=2))\n",
    "cnn.add(BatchNormalization())\n",
    "cnn.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening \n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full connection with neurons\n",
    "cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "cnn.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 64s 255ms/step - loss: 1.3102 - accuracy: 0.5786 - val_loss: 0.6537 - val_accuracy: 0.6225\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.6735 - accuracy: 0.6235 - val_loss: 0.6501 - val_accuracy: 0.6365\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 67s 266ms/step - loss: 0.6173 - accuracy: 0.6481 - val_loss: 0.6542 - val_accuracy: 0.6450\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.6049 - accuracy: 0.6643 - val_loss: 0.5716 - val_accuracy: 0.7060\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 58s 231ms/step - loss: 0.5914 - accuracy: 0.6821 - val_loss: 0.5714 - val_accuracy: 0.7075\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 57s 228ms/step - loss: 0.5777 - accuracy: 0.6919 - val_loss: 0.5823 - val_accuracy: 0.6980\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 57s 230ms/step - loss: 0.5653 - accuracy: 0.7066 - val_loss: 0.5930 - val_accuracy: 0.7005\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 54s 216ms/step - loss: 0.5568 - accuracy: 0.7069 - val_loss: 0.5754 - val_accuracy: 0.7060\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.5573 - accuracy: 0.7138 - val_loss: 0.6549 - val_accuracy: 0.6490\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.5442 - accuracy: 0.7186 - val_loss: 0.8139 - val_accuracy: 0.6290\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 54s 218ms/step - loss: 0.5417 - accuracy: 0.7240 - val_loss: 0.5186 - val_accuracy: 0.7425\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.5321 - accuracy: 0.7315 - val_loss: 0.5102 - val_accuracy: 0.7490\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.5282 - accuracy: 0.7343 - val_loss: 0.5371 - val_accuracy: 0.7430\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.5196 - accuracy: 0.7389 - val_loss: 0.5636 - val_accuracy: 0.7180\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.5169 - accuracy: 0.7458 - val_loss: 0.4970 - val_accuracy: 0.7520\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.5010 - accuracy: 0.7538 - val_loss: 0.4783 - val_accuracy: 0.7625\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 56s 226ms/step - loss: 0.5030 - accuracy: 0.7510 - val_loss: 0.4717 - val_accuracy: 0.7840\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 62s 247ms/step - loss: 0.4956 - accuracy: 0.7530 - val_loss: 0.6308 - val_accuracy: 0.6850\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.4828 - accuracy: 0.7640 - val_loss: 0.5285 - val_accuracy: 0.7215\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.4812 - accuracy: 0.7625 - val_loss: 0.4634 - val_accuracy: 0.7850\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.4890 - accuracy: 0.7648 - val_loss: 0.4512 - val_accuracy: 0.7975\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 56s 223ms/step - loss: 0.4855 - accuracy: 0.7598 - val_loss: 0.4848 - val_accuracy: 0.7780\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 54s 216ms/step - loss: 0.4787 - accuracy: 0.7689 - val_loss: 0.5018 - val_accuracy: 0.7680\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.4779 - accuracy: 0.7688 - val_loss: 0.5469 - val_accuracy: 0.7315\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.4676 - accuracy: 0.7742 - val_loss: 0.4449 - val_accuracy: 0.8060\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.4670 - accuracy: 0.7724 - val_loss: 0.4222 - val_accuracy: 0.8085\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.4617 - accuracy: 0.7829 - val_loss: 0.4185 - val_accuracy: 0.8035\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 53s 212ms/step - loss: 0.4615 - accuracy: 0.7840 - val_loss: 0.5526 - val_accuracy: 0.7065\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.4602 - accuracy: 0.7786 - val_loss: 0.4540 - val_accuracy: 0.7870\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 54s 217ms/step - loss: 0.4533 - accuracy: 0.7860 - val_loss: 0.4517 - val_accuracy: 0.7930\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.4434 - accuracy: 0.7950 - val_loss: 0.4240 - val_accuracy: 0.8080\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.4421 - accuracy: 0.7922 - val_loss: 0.5984 - val_accuracy: 0.7110\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.4443 - accuracy: 0.7905 - val_loss: 0.4734 - val_accuracy: 0.7740\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 55s 219ms/step - loss: 0.4381 - accuracy: 0.7929 - val_loss: 0.4049 - val_accuracy: 0.8190\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 56s 222ms/step - loss: 0.4369 - accuracy: 0.7925 - val_loss: 0.4644 - val_accuracy: 0.7730\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 55s 219ms/step - loss: 0.4320 - accuracy: 0.7995 - val_loss: 0.4295 - val_accuracy: 0.8105\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.4388 - accuracy: 0.7960 - val_loss: 0.3974 - val_accuracy: 0.8185\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 55s 220ms/step - loss: 0.4311 - accuracy: 0.7951 - val_loss: 0.5937 - val_accuracy: 0.7115\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 57s 226ms/step - loss: 0.4315 - accuracy: 0.7949 - val_loss: 0.4934 - val_accuracy: 0.7855\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 55s 222ms/step - loss: 0.4226 - accuracy: 0.8030 - val_loss: 0.3772 - val_accuracy: 0.8290\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 54s 215ms/step - loss: 0.4232 - accuracy: 0.8044 - val_loss: 0.3939 - val_accuracy: 0.8245\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.4238 - accuracy: 0.8027 - val_loss: 0.6640 - val_accuracy: 0.6915\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 53s 214ms/step - loss: 0.4244 - accuracy: 0.7951 - val_loss: 0.4449 - val_accuracy: 0.8040\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.4114 - accuracy: 0.8056 - val_loss: 0.5207 - val_accuracy: 0.7550\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.4205 - accuracy: 0.8051 - val_loss: 0.3639 - val_accuracy: 0.8390\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 54s 216ms/step - loss: 0.4231 - accuracy: 0.8044 - val_loss: 0.4143 - val_accuracy: 0.8100\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 53s 212ms/step - loss: 0.4159 - accuracy: 0.8046 - val_loss: 0.4214 - val_accuracy: 0.8145\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 53s 212ms/step - loss: 0.4208 - accuracy: 0.8048 - val_loss: 0.3873 - val_accuracy: 0.8305\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.4097 - accuracy: 0.8080 - val_loss: 0.4566 - val_accuracy: 0.7940\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.4124 - accuracy: 0.8090 - val_loss: 0.4299 - val_accuracy: 0.8020\n"
     ]
    }
   ],
   "source": [
    "cnn.fit(x=training_set, validation_data= testing_set, epochs=50)\n",
    "cnn.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('Data/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'dog'\n",
    "else:\n",
    "  prediction = 'cat'\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
